{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting false statements with L1-regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z2TkU89M0Ar6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_factcheck.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame includes\n",
    "\n",
    "*  a `statement` field, which has the text of the statement, \n",
    "* and a `label_binary` field indicating if it is false (1) or true/mostly true (0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>label_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Kesha Rogers is not a Democrat.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>The newly created state Immigration Enforcemen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>On support for the Bridge to Nowhere.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>The Congressional Budget Office, a nonpartisan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>Says Gov. Scott Walker is cooking the books by...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              statement  label_binary\n",
       "262                     Kesha Rogers is not a Democrat.             1\n",
       "214   The newly created state Immigration Enforcemen...             1\n",
       "346               On support for the Bridge to Nowhere.             1\n",
       "1906  The Congressional Budget Office, a nonpartisan...             0\n",
       "658   Says Gov. Scott Walker is cooking the books by...             1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into a training and test set. Note that the data is ordered by class, so we *must* shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_str, Xts_str, ytr, yts = train_test_split(df['statement'].values, df['label_binary'].values, shuffle=True, random_state=0, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, we will need to get this text into some kind of numeric representation. We will use a basic approach called \"bag of words\", that works as follows:\n",
    "\n",
    "0. Remove the \"trivial\" words that you want to ignore, such as \"the\", \"an\", \"has\", etc. from the text.\n",
    "1. Compile a \"vocabulary\" - a list of all of the words in the dataset - with integer indices from 0 to $d-1$.\n",
    "2. Convert every sample into a $d$-dimensional vector $x$, by letting the $j$ th coordinate of $x$ be the number of occurences of the $j$ th words in the document. (This number is often called the \"term frequency\".)\n",
    "\n",
    "Now, we have a set of vectors - one for each sample - containing the frequency of each word."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `sklearn` implementation of this, which is called `CountVectorizer`. You may refer to the [`CountVectorizer` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html).\n",
    "\n",
    "We will create an instance of a `CountVectorizer`, passing `stop_words = 'english'` and leaving other arguments at their default values.\n",
    "\n",
    "Create `Xtr_vec` by fitting it on the training data, then using it to transform the training data. Use the already fitted vectorizer to transform the test data, to create `Xts_vec`. (This is the 'typical' data pre-processing pattern, where data pre-processing always uses the statistics of the training data *only*.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "vec = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training data\n",
    "Xtr_vec = vec.fit_transform(Xtr_str)\n",
    "\n",
    "# Use the fitted vectorizer to transform the test data\n",
    "Xts_vec = vec.transform(Xts_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 4569)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr_vec.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You notice that in its vector representation, the data has several thousand features. You wonder if maybe you can use a sparse representation of this data in your classifier. You decide to try L1 regularization, which you know tends to fit sparse coefficients."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, use K-fold CV with 5 folds to evaluate different values of `C` in the list defined by\n",
    "\n",
    "```\n",
    "np.logspace(-3, 3, num=20)\n",
    "```\n",
    "\n",
    "for an `l1` penalty in the `LogisticRegression`.  Iterate over the K-fold split (don't shuffle the data again!) and in each fold:\n",
    "\n",
    "* train a `LogisticRegression` with an `l1` penalty and the specified value of `C`. Also set `random_state = 0`, and use the `liblinear` solver. Leave other settings at their default values.\n",
    "* compute the accuracy of the model on the validation data, and save it in `acc_val`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_test = np.logspace(-3, 3, num=20)\n",
    "# Note: use this C_test array to implement your solution, and do *not* re-define C_test.\n",
    "# The grader will evaluate your solution over a *DIFFERENT* array, that is also named C_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "\n",
    "nfold = 5\n",
    "acc_val = np.zeros((len(C_test), nfold))\n",
    "\n",
    "kf = KFold(n_splits=nfold)\n",
    "  \n",
    "# Iterate over each fold\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kf.split(Xtr_vec)):\n",
    "    X_train, X_val = Xtr_vec[train_idx], Xtr_vec[val_idx]\n",
    "    y_train, y_val = ytr[train_idx], ytr[val_idx]\n",
    "    \n",
    "    # Iterate over each C value\n",
    "    for c_idx, C in enumerate(C_test):\n",
    "        # Train a LogisticRegression model with L1 penalty and the specified value of C\n",
    "        clf = LogisticRegression(solver='liblinear', penalty='l1', C=C, random_state=0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the validation data\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "        \n",
    "        # Compute and store the accuracy of the model on the validation data\n",
    "        acc_val[c_idx, fold_idx] = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# acc_val now contains the accuracy for each value of C and each fold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the value of C that had the best validation accuracy, and save it in `C_best`. (Note: do not hard-code this value!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "\n",
    "acc_mean = np.mean(acc_val, axis=1)\n",
    "\n",
    "# Find the value of C that gives the highest mean accuracy\n",
    "C_best = C_test[np.argmax(acc_mean)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the entire training set, train a `LogisticRegression` with `l1` penalty and this value of `C`, `random_state = 0`, `liblinear` solver, and leave other settings at their default values. Get the accuracy of this model on the test data, and save it in `acc_best`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "clf_best = LogisticRegression(solver='liblinear', penalty='l1', C=C_best, random_state=0)\n",
    "clf_best.fit(Xtr_vec, ytr)  # Use Xtr_vec and ytr for training\n",
    "\n",
    "# Get the accuracy on the test data\n",
    "y_hat = clf_best.predict(Xts_vec)  # Use Xts_vec for testing\n",
    "acc_best = accuracy_score(yts, y_hat)  # Calculate accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also check whether this model achieves your goal of \"zeroing\" out many features - use [`np.count_nonzero`](https://numpy.org/doc/stable/reference/generated/numpy.count_nonzero.html) to count the number of model coefficients that are *not* zero. Save this count in `count_best`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "count_best = np.count_nonzero(clf_best.coef_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, find the value of C that is best according to the one-SE rule, and save it in `C_one_se`. (Note: do not hard-code this value!) Remember that C is the *inverse* of the strength of the regularization penalty, e.g. a larger value of C means *less* regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "# 1. Find the best mean validation accuracy\n",
    "mean_val_accuracy = np.mean(acc_val, axis=1)\n",
    "best_mean_accuracy = np.max(mean_val_accuracy)\n",
    "\n",
    "# 2. Calculate the standard deviation of validation accuracies\n",
    "std_val_accuracy = np.std(acc_val, axis=1)\n",
    "\n",
    "# 3. Find the largest C that is within one standard error of the best mean accuracy\n",
    "threshold = best_mean_accuracy - std_val_accuracy\n",
    "C_one_se = C_test[np.where(mean_val_accuracy >= threshold)[0][-1]]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the entire training set, train a `LogisticRegression` with `l1` penalty and this value of `C`, `random_state = 0`, `liblinear` solver, and leave other settings at their default values. Get the accuracy of this model on the test data, and save it in `acc_one_se`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "# Train a LogisticRegression model using the best C from the one-SE rule\n",
    "clf_one_se = LogisticRegression(solver='liblinear', penalty='l1', C=C_one_se, random_state=0)\n",
    "clf_one_se.fit(Xtr_vec, ytr)  # Train on the entire training set\n",
    "\n",
    "# Get the accuracy of this model on the test data\n",
    "yts_pred = clf_one_se.predict(Xts_vec)  # Make predictions on the test set\n",
    "acc_one_se = accuracy_score(yts, yts_pred)  # Calculate accuracy on test set\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also check whether this model achieves your goal of \"zeroing\" out many features - use [`np.count_nonzero`](https://numpy.org/doc/stable/reference/generated/numpy.count_nonzero.html) to count the number of model coefficients that are *not* zero. Save this count in `count_one_se`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "# Train a LogisticRegression model using the best C from the one-SE rule\n",
    "clf_one_se = LogisticRegression(solver='liblinear', penalty='l1', C=C_one_se, random_state=0)\n",
    "clf_one_se.fit(Xtr_vec, ytr)  # Train on the entire training set\n",
    "\n",
    "# Get the accuracy of this model on the test data\n",
    "yts_pred = clf_one_se.predict(Xts_vec)  # Make predictions on the test set\n",
    "acc_one_se = accuracy_score(yts, yts_pred)  # Calculate accuracy on test set\n",
    "\n",
    "# Check how many coefficients are non-zero\n",
    "count_one_se = np.count_nonzero(clf_one_se.coef_)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Workbook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
